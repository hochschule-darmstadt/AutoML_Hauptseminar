{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1e9229-7c6c-41fe-910b-001272168ea5",
   "metadata": {},
   "source": [
    "# Das Notebook wurde lokal ausgeführt, dient der Veranschaulichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e23bd5e3-b255-4c78-9bd3-8df9a5e04415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atm import ATM\n",
    "\n",
    "atm = ATM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62946b58-1a76-43fc-8f65-4b1727dd250e",
   "metadata": {},
   "source": [
    "# Classification Run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05432e9d-d9fe-4782-a021-e2834bf5ba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset /Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92 Classifiers [10:21, 15.63s/ Classifiers]Walltime budget has run out!\n",
      "Datarun 9 has ended.\n",
      "92 Classifiers [10:21,  6.75s/ Classifiers]\n"
     ]
    }
   ],
   "source": [
    "results = atm.run(\n",
    "    train_path='/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv',\n",
    "    test_path = '/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_test_copy.csv', #default none, splits train set automatically\n",
    "    name = 'Classification_Set',\n",
    "    class_column = 'Result',\n",
    "    budget = 10,\n",
    "    budget_type = 'walltime',\n",
    "    gridding = 0, #default 0 no gridding, gridding factor\n",
    "    k_window = 0, #default\n",
    "    methods = ['logreg', 'dt', 'knn'], #default\n",
    "    metric = 'f1', #default\n",
    "    r_minimum = 2, #default\n",
    "    run_per_partition = False, #default\n",
    "    score_target = 'cv', #default\n",
    "    #priority = '', #no default given\n",
    "    selector = 'uniform', #default\n",
    "    tuner = 'uniform' #default\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "380cc70d-3523-47f6-9a0b-c7fef08fa231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datarun 9 summary:\n",
      "\tDataset: '/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv'\n",
      "\tColumn Name: 'Result'\n",
      "\tJudgment Metric: 'f1'\n",
      "\tClassifiers Tested: 92\n",
      "\tElapsed Time: 0:10:21.020279\n"
     ]
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93853b23-3b19-4a36-a2ae-ad3817a7fa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier id: 493\n",
       "Classifier type: knn\n",
       "Params chosen: \n",
       "\tn_neighbors: 13\n",
       "\tleaf_size: 21\n",
       "\tweights: distance\n",
       "\talgorithm: kd_tree\n",
       "\tmetric: manhattan\n",
       "\t_scale: True\n",
       "Cross Validation Score: 0.972 +- 0.016\n",
       "Test Score: 0.916"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_best_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71c1c5d6-4e69-48d6-896b-002768fb620e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_judgment_metric</th>\n",
       "      <th>cv_judgment_metric_stdev</th>\n",
       "      <th>id</th>\n",
       "      <th>test_judgment_metric</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9719887638</td>\n",
       "      <td>0.0160374138</td>\n",
       "      <td>493</td>\n",
       "      <td>0.9155074704</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9717583491</td>\n",
       "      <td>0.0161213826</td>\n",
       "      <td>521</td>\n",
       "      <td>0.9160659114</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9717583491</td>\n",
       "      <td>0.0161213826</td>\n",
       "      <td>506</td>\n",
       "      <td>0.9160659114</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9713969103</td>\n",
       "      <td>0.0164580978</td>\n",
       "      <td>503</td>\n",
       "      <td>0.9179566563</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9712910829</td>\n",
       "      <td>0.0152946800</td>\n",
       "      <td>544</td>\n",
       "      <td>0.9089963599</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cv_judgment_metric cv_judgment_metric_stdev   id test_judgment_metric  rank\n",
       "0       0.9719887638             0.0160374138  493         0.9155074704   1.0\n",
       "1       0.9717583491             0.0161213826  521         0.9160659114   2.5\n",
       "2       0.9717583491             0.0161213826  506         0.9160659114   2.5\n",
       "3       0.9713969103             0.0164580978  503         0.9179566563   4.0\n",
       "4       0.9712910829             0.0152946800  544         0.9089963599   5.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = results.get_scores()\n",
    "scores.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7c79b-9a71-4c06-8631-d96205ba67e4",
   "metadata": {},
   "source": [
    "# Classification Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59487d0b-811b-47e7-bf1a-7177d0ebd310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset /Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "129 Classifiers [10:30, 19.23s/ Classifiers]Walltime budget has run out!\n",
      "Datarun 10 has ended.\n",
      "129 Classifiers [10:30,  4.89s/ Classifiers]\n"
     ]
    }
   ],
   "source": [
    "results2 = atm.run(\n",
    "    train_path='/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv',\n",
    "    test_path = '/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_test_copy.csv', #default, splits train set automatically\n",
    "    name = 'Classification_Set',\n",
    "    class_column = 'Result',\n",
    "    budget = 10,\n",
    "    budget_type = 'walltime',\n",
    "    gridding = 0, #default 0 no gridding, gridding factor\n",
    "    k_window = 0, #default\n",
    "    methods = ['logreg', 'dt', 'knn'], #default\n",
    "    metric = 'f1', #default\n",
    "    r_minimum = 2, #default\n",
    "    run_per_partition = False, #default\n",
    "    score_target = 'cv', #default\n",
    "    #priority = '', #no default given\n",
    "    selector = 'uniform', #default\n",
    "    tuner = 'uniform'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eb214e5-e246-42a9-8c10-39909946910f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datarun 10 summary:\n",
      "\tDataset: '/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv'\n",
      "\tColumn Name: 'Result'\n",
      "\tJudgment Metric: 'f1'\n",
      "\tClassifiers Tested: 129\n",
      "\tElapsed Time: 0:10:30.299203\n"
     ]
    }
   ],
   "source": [
    "results2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0375778f-c99d-4bb5-98b7-c19ad0d97af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier id: 584\n",
       "Classifier type: knn\n",
       "Params chosen: \n",
       "\tn_neighbors: 3\n",
       "\tp: 1\n",
       "\tweights: distance\n",
       "\talgorithm: brute\n",
       "\tmetric: minkowski\n",
       "\t_scale: True\n",
       "Cross Validation Score: 0.972 +- 0.016\n",
       "Test Score: 0.913"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2.get_best_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8b8c10d-dbbb-4b2a-a797-ff35faa67099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_judgment_metric</th>\n",
       "      <th>cv_judgment_metric_stdev</th>\n",
       "      <th>id</th>\n",
       "      <th>test_judgment_metric</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9723567119</td>\n",
       "      <td>0.0158198611</td>\n",
       "      <td>584</td>\n",
       "      <td>0.9129411765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9717547187</td>\n",
       "      <td>0.0157811761</td>\n",
       "      <td>610</td>\n",
       "      <td>0.9172699069</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9714878147</td>\n",
       "      <td>0.0157781476</td>\n",
       "      <td>660</td>\n",
       "      <td>0.9069286453</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9712815089</td>\n",
       "      <td>0.0154325105</td>\n",
       "      <td>686</td>\n",
       "      <td>0.9212214524</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9712526409</td>\n",
       "      <td>0.0160795481</td>\n",
       "      <td>621</td>\n",
       "      <td>0.9169039607</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cv_judgment_metric cv_judgment_metric_stdev   id test_judgment_metric  rank\n",
       "0       0.9723567119             0.0158198611  584         0.9129411765   1.0\n",
       "1       0.9717547187             0.0157811761  610         0.9172699069   2.0\n",
       "2       0.9714878147             0.0157781476  660         0.9069286453   3.0\n",
       "3       0.9712815089             0.0154325105  686         0.9212214524   4.0\n",
       "4       0.9712526409             0.0160795481  621         0.9169039607   5.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = results2.get_scores()\n",
    "scores.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ead2804-329e-4ab6-967d-15b102522d20",
   "metadata": {},
   "source": [
    "# Classification Run 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fc0398c-4d19-4fc7-9806-ba129ab31837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset /Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84 Classifiers [10:02,  5.35s/ Classifiers]Walltime budget has run out!\n",
      "Datarun 11 has ended.\n",
      "84 Classifiers [10:02,  7.17s/ Classifiers]\n"
     ]
    }
   ],
   "source": [
    "results3 = atm.run(\n",
    "    train_path='/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv',\n",
    "    test_path = '/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_test_copy.csv', #default, splits train set automatically\n",
    "    name = 'Classification_Set',\n",
    "    class_column = 'Result',\n",
    "    budget = 10,\n",
    "    budget_type = 'walltime',\n",
    "    gridding = 0, #default 0 no gridding, gridding factor\n",
    "    k_window = 0, #default\n",
    "    methods = ['logreg', 'dt', 'knn'], #default\n",
    "    metric = 'f1', #default\n",
    "    r_minimum = 2, #default\n",
    "    run_per_partition = False, #default\n",
    "    score_target = 'cv', #default\n",
    "    #priority = '', #no default given\n",
    "    selector = 'uniform', #default\n",
    "    tuner = 'uniform'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a319c8b1-43d2-4a9a-8426-c598fb2ac889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datarun 11 summary:\n",
      "\tDataset: '/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv'\n",
      "\tColumn Name: 'Result'\n",
      "\tJudgment Metric: 'f1'\n",
      "\tClassifiers Tested: 84\n",
      "\tElapsed Time: 0:10:02.546677\n"
     ]
    }
   ],
   "source": [
    "results3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43bdd89c-8489-4ce3-9434-cdb2f5b6e9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier id: 731\n",
       "Classifier type: knn\n",
       "Params chosen: \n",
       "\tn_neighbors: 11\n",
       "\tleaf_size: 11\n",
       "\tweights: distance\n",
       "\talgorithm: kd_tree\n",
       "\tmetric: manhattan\n",
       "\t_scale: True\n",
       "Cross Validation Score: 0.972 +- 0.015\n",
       "Test Score: 0.917"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3.get_best_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "009dd1ca-e5f1-457d-8021-92d80b60c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_judgment_metric</th>\n",
       "      <th>cv_judgment_metric_stdev</th>\n",
       "      <th>id</th>\n",
       "      <th>test_judgment_metric</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9719705047</td>\n",
       "      <td>0.0154039346</td>\n",
       "      <td>731</td>\n",
       "      <td>0.9167958656</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9718513887</td>\n",
       "      <td>0.0154558979</td>\n",
       "      <td>749</td>\n",
       "      <td>0.9175071115</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9717547187</td>\n",
       "      <td>0.0157811761</td>\n",
       "      <td>705</td>\n",
       "      <td>0.9167958656</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9711199958</td>\n",
       "      <td>0.0162417393</td>\n",
       "      <td>773</td>\n",
       "      <td>0.9197341513</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9707414749</td>\n",
       "      <td>0.0168301138</td>\n",
       "      <td>761</td>\n",
       "      <td>0.9172661871</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cv_judgment_metric cv_judgment_metric_stdev   id test_judgment_metric  rank\n",
       "0       0.9719705047             0.0154039346  731         0.9167958656   1.0\n",
       "1       0.9718513887             0.0154558979  749         0.9175071115   2.0\n",
       "2       0.9717547187             0.0157811761  705         0.9167958656   3.0\n",
       "3       0.9711199958             0.0162417393  773         0.9197341513   4.0\n",
       "4       0.9707414749             0.0168301138  761         0.9172661871   5.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = results3.get_scores()\n",
    "scores.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a831bc-f4bd-4ef7-906f-4cc2836fc84f",
   "metadata": {},
   "source": [
    "# Classification Run 4 - Test other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef1e0581-97b8-45ea-9441-79feae4466d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset /Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5 Classifiers [06:17, 60.55s/ Classifiers] Error testing classifier: datarun=<ID = 20, dataset ID = 22, strategy = uniform___uniform, budget = walltime (10), status: pending>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/worker.py\", line 399, in run_classifier\n",
      "    model, metrics = self.test_classifier(hyperpartition.method, params)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/worker.py\", line 207, in test_classifier\n",
      "    metrics = model.train_test(self.dataset)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/classifier.py\", line 213, in train_test\n",
      "    self._make_pipeline()\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/classifier.py\", line 103, in _make_pipeline\n",
      "    classifier = self.class_(**hyperparameters)\n",
      "TypeError: __init__() got an unexpected keyword argument 'n_iter'\n",
      "\n",
      "Something went wrong. Sleeping 5 seconds.\n",
      "\n",
      "5 Classifiers [06:22, 76.47s/ Classifiers]\n",
      "\n",
      "6 Classifiers [00:22, 22.72s/ Classifiers]\u001b[A\n",
      "7 Classifiers [02:23, 80.21s/ Classifiers]\u001b[A\n",
      "8 Classifiers [02:50, 55.99s/ Classifiers]\u001b[A\n",
      "9 Classifiers [03:32, 50.43s/ Classifiers]\u001b[A\n",
      "10 Classifiers [03:36, 33.76s/ Classifiers]\u001b[A\n",
      "11 Classifiers [03:38, 22.82s/ Classifiers]\u001b[AWalltime budget has run out!\n",
      "Datarun 20 has ended.\n",
      "11 Classifiers [03:38, 36.34s/ Classifiers]\n"
     ]
    }
   ],
   "source": [
    "results3 = atm.run(\n",
    "    train_path='/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv',\n",
    "    test_path = '/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_test_copy.csv', #default, splits train set automatically\n",
    "    name = 'Classification_Set',\n",
    "    class_column = 'Result',\n",
    "    budget = 10,\n",
    "    budget_type = 'walltime',\n",
    "    gridding = 0, #default 0 no gridding, gridding factor\n",
    "    k_window = 0, #default\n",
    "    methods = ['svm','et', 'rf','mnb', 'bnb', 'gp','pa','mlp','ada'], \n",
    "    #methods = ['gnb'], #default\n",
    "    metric = 'f1', #default\n",
    "    r_minimum = 2, #default\n",
    "    run_per_partition = False, #default\n",
    "    score_target = 'cv', #default\n",
    "    #priority = '', #no default given\n",
    "    selector = 'uniform', #default\n",
    "    tuner = 'uniform'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce2539de-4a83-4e05-b346-37c2fce02336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datarun 20 summary:\n",
      "\tDataset: '/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/phishing_train_copy.csv'\n",
      "\tColumn Name: 'Result'\n",
      "\tJudgment Metric: 'f1'\n",
      "\tClassifiers Tested: 12\n",
      "\tElapsed Time: 0:10:00.437027\n"
     ]
    }
   ],
   "source": [
    "results4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b59961c4-f055-478d-838d-574fbd25dc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier id: 814\n",
       "Classifier type: mlp\n",
       "Params chosen: \n",
       "\talpha: 0.006978834826973907\n",
       "\tlearning_rate_init: 0.4998432944391181\n",
       "\thidden_layer_sizes[0]: 255\n",
       "\thidden_layer_sizes[1]: 149\n",
       "\thidden_layer_sizes[2]: 253\n",
       "\tsolver: sgd\n",
       "\tactivation: relu\n",
       "\tlen(hidden_layer_sizes): 3\n",
       "\tlearning_rate: adaptive\n",
       "\tbatch_size: auto\n",
       "\t_scale: True\n",
       "Cross Validation Score: 0.979 +- 0.009\n",
       "Test Score: 0.922"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3.get_best_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "907db909-5c64-466d-bc01-7782fd4064a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_judgment_metric</th>\n",
       "      <th>cv_judgment_metric_stdev</th>\n",
       "      <th>id</th>\n",
       "      <th>test_judgment_metric</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9786610246</td>\n",
       "      <td>0.0086267728</td>\n",
       "      <td>814</td>\n",
       "      <td>0.9221717037</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9748580659</td>\n",
       "      <td>0.0126941864</td>\n",
       "      <td>807</td>\n",
       "      <td>0.8993861756</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9747092506</td>\n",
       "      <td>0.0129469926</td>\n",
       "      <td>816</td>\n",
       "      <td>0.9034334764</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9746721169</td>\n",
       "      <td>0.0103969819</td>\n",
       "      <td>815</td>\n",
       "      <td>0.9207446809</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9745934060</td>\n",
       "      <td>0.0105227180</td>\n",
       "      <td>813</td>\n",
       "      <td>0.9091871856</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cv_judgment_metric cv_judgment_metric_stdev   id test_judgment_metric  rank\n",
       "0       0.9786610246             0.0086267728  814         0.9221717037   1.0\n",
       "1       0.9748580659             0.0126941864  807         0.8993861756   2.0\n",
       "2       0.9747092506             0.0129469926  816         0.9034334764   3.0\n",
       "3       0.9746721169             0.0103969819  815         0.9207446809   4.0\n",
       "4       0.9745934060             0.0105227180  813         0.9091871856   5.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = results3.get_scores()\n",
    "scores.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfcc706-3998-4fc7-bc6e-de8f1e78b6a1",
   "metadata": {},
   "source": [
    "# Regression wird nicht unterstützt, hier der Versuch dazu um zu sehen was passiert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c704c36e-b69d-4309-a2e2-80eb3ea80bf3",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "969600d9-e26b-4ed9-bab3-b6a9d0a00f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset /Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Regression_fixed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8 Classifiers [4:36:49, 2076.18s/ Classifiers]\n",
      "Error testing classifier: datarun=<ID = 8, dataset ID = 9, strategy = uniform___uniform, budget = walltime (1), status: pending>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/worker.py\", line 399, in run_classifier\n",
      "    model, metrics = self.test_classifier(hyperpartition.method, params)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/worker.py\", line 207, in test_classifier\n",
      "    metrics = model.train_test(self.dataset)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/classifier.py\", line 210, in train_test\n",
      "    X_test, y_test = self.encoder.transform(test_data)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/encoder.py\", line 72, in transform\n",
      "    y = self.label_encoder.transform(labels)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 257, in transform\n",
      "    _, y = _encode(y, uniques=self.classes_, encode=True)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 110, in _encode\n",
      "    return _encode_numpy(values, uniques, encode)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 49, in _encode_numpy\n",
      "    % str(diff))\n",
      "ValueError: y contains previously unseen labels: [0.0392, 0.0571, 0.0658, 0.0673, 0.0674, 0.0677, 0.0754, 0.0758, 0.0759, 0.0789, 0.0805, 0.0933, 0.0947, 0.0983, 0.10099999999999999, 0.10400000000000001, 0.1065, 0.1067, 0.1129, 0.1164, 0.1165, 0.1169, 0.1192, 0.1215, 0.1224, 0.1232, 0.1237, 0.1264, 0.127, 0.1273, 0.1288, 0.1314, 0.1325, 0.1351, 0.1388, 0.1415, 0.1423, 0.1471, 0.1473, 0.1488, 0.1489, 0.15, 0.1507, 0.1514, 0.1521, 0.153, 0.156, 0.1565, 0.1566, 0.157, 0.16, 0.1613, 0.1617, 0.165, 0.1665, 0.1686, 0.1687, 0.1692, 0.1702, 0.1718, 0.1723, 0.1725, 0.1739, 0.175, 0.1752, 0.1765, 0.1773, 0.1781, 0.1807, 0.1808, 0.18100000000000002, 0.1835, 0.1841, 0.1842, 0.1856, 0.1869, 0.1872, 0.1878, 0.18899999999999997, 0.1899, 0.1903, 0.1907, 0.1913, 0.1922, 0.1925, 0.1941, 0.1949, 0.1958, 0.19699999999999998, 0.1975, 0.1979, 0.1998, 0.2009, 0.2014, 0.2021, 0.2023, 0.2029, 0.2042, 0.2054, 0.2058, 0.2076, 0.2078, 0.209, 0.2104, 0.2117, 0.213, 0.2134, 0.2167, 0.2176, 0.2179, 0.2181, 0.2209, 0.2218, 0.2251, 0.22699999999999998, 0.2273, 0.2298, 0.2318, 0.2323, 0.2338, 0.2349, 0.237, 0.2373, 0.2375, 0.2377, 0.2378, 0.23800000000000002, 0.2383, 0.2386, 0.2396, 0.2397, 0.2401, 0.2407, 0.2414, 0.2429, 0.2435, 0.2458, 0.2462, 0.2497, 0.2515, 0.2534, 0.2535, 0.2537, 0.2555, 0.2557, 0.2568, 0.257, 0.2576, 0.2579, 0.2583, 0.2585, 0.2588, 0.2594, 0.2595, 0.2598, 0.2601, 0.2605, 0.2606, 0.2612, 0.2623, 0.2633, 0.2637, 0.264, 0.2642, 0.2647, 0.2684, 0.2685, 0.2688, 0.2692, 0.2699, 0.27, 0.2703, 0.2704, 0.2711, 0.27399999999999997, 0.275, 0.2754, 0.2759, 0.2767, 0.2772, 0.2777, 0.2783, 0.2786, 0.28, 0.2807, 0.2808, 0.2852, 0.2862, 0.2868, 0.2876, 0.2883, 0.2888, 0.2889, 0.2893, 0.2904, 0.2905, 0.2912, 0.2922, 0.2932, 0.2942, 0.2944, 0.2946, 0.2966, 0.297, 0.2993, 0.2995, 0.3006, 0.302, 0.3022, 0.3035, 0.3036, 0.3043, 0.3051, 0.3052, 0.3072, 0.3082, 0.3088, 0.3091, 0.3092, 0.3094, 0.3095, 0.3103, 0.3125, 0.3127, 0.3135, 0.3164, 0.3167, 0.3169, 0.3176, 0.3185, 0.3191, 0.3194, 0.3203, 0.3204, 0.3209, 0.3237, 0.3247, 0.3255, 0.3264, 0.3268, 0.3272, 0.3273, 0.3276, 0.3292, 0.3293, 0.3321, 0.3336, 0.3346, 0.3352, 0.3355, 0.3356, 0.3357, 0.3368, 0.3397, 0.34, 0.3402, 0.3406, 0.3414, 0.3416, 0.3426, 0.3435, 0.3439, 0.3454, 0.3458, 0.3462, 0.3473, 0.3483, 0.349, 0.3492, 0.3493, 0.3498, 0.3511, 0.3515, 0.3518, 0.3521, 0.3529, 0.3541, 0.3547, 0.3548, 0.3562, 0.35700000000000004, 0.3573, 0.3578, 0.3598, 0.3602, 0.3604, 0.3609, 0.3615, 0.3622, 0.3625, 0.3631, 0.3641, 0.3643, 0.3649, 0.3670000000000001, 0.3692, 0.3695, 0.3701, 0.3702, 0.3711, 0.3715, 0.3718, 0.3719, 0.3729, 0.3737, 0.374, 0.3746, 0.3753, 0.3756, 0.3764, 0.3767, 0.3768, 0.3778, 0.3783, 0.3786, 0.3787, 0.3804, 0.3808, 0.384, 0.3843, 0.3848, 0.3873, 0.3881, 0.3893, 0.3906, 0.3927, 0.3928, 0.3929, 0.3944, 0.3948, 0.3952, 0.3956, 0.3962, 0.3975, 0.3981, 0.4006, 0.4007, 0.4015, 0.4017, 0.4018, 0.4021, 0.4023, 0.4036, 0.4053, 0.4058, 0.4067, 0.4069, 0.40700000000000003, 0.4091, 0.4098, 0.4101, 0.4112, 0.4119, 0.4133, 0.4139, 0.4146, 0.4148, 0.418, 0.4189, 0.4213, 0.4219, 0.42200000000000004, 0.4222, 0.4225, 0.4234, 0.4241, 0.4263, 0.429, 0.4294, 0.43, 0.4308, 0.431, 0.4320000000000001, 0.4333, 0.434, 0.4343, 0.4355, 0.4365, 0.4371, 0.4386, 0.4391, 0.4411, 0.442, 0.4434, 0.444, 0.4449, 0.4452, 0.4458, 0.4461, 0.44799999999999995, 0.4495, 0.4503, 0.4513, 0.452, 0.4538, 0.4543, 0.4547, 0.4555, 0.4557, 0.4558, 0.4576, 0.4608, 0.466, 0.4666, 0.4674, 0.4675, 0.4681, 0.4697, 0.4703, 0.4704, 0.47100000000000003, 0.4711, 0.4719, 0.4725, 0.4734, 0.4749, 0.4756, 0.4757, 0.47600000000000003, 0.4769, 0.4775, 0.4779, 0.4792, 0.4796, 0.4802, 0.4814, 0.4831, 0.4838, 0.4843, 0.4844, 0.4845, 0.4847, 0.485, 0.4852, 0.4862, 0.4873, 0.4879, 0.4882, 0.4889, 0.4894, 0.4896, 0.4929, 0.495, 0.4954, 0.4982, 0.4983, 0.5006, 0.5027, 0.5032, 0.5037, 0.5038, 0.505, 0.5062, 0.5072, 0.5073, 0.5074, 0.5076, 0.5079, 0.508, 0.5115, 0.512, 0.5126, 0.5128, 0.5142, 0.5149, 0.5155, 0.5185, 0.5192, 0.5208, 0.521, 0.5212, 0.522, 0.5231, 0.5235, 0.5251, 0.5263, 0.5267, 0.5277, 0.5281, 0.5288, 0.5299, 0.5303, 0.5307, 0.5309, 0.5321, 0.5332, 0.5334, 0.5345, 0.5348, 0.5351, 0.5352, 0.5367, 0.5368, 0.5369, 0.5375, 0.5384, 0.539, 0.5393, 0.5396, 0.5404, 0.541, 0.5412, 0.5417, 0.5444, 0.5449, 0.5458, 0.546, 0.5466, 0.5468, 0.5476, 0.5482, 0.5487, 0.5503, 0.5518, 0.5537, 0.5567, 0.5582, 0.5583, 0.5602, 0.5607, 0.5626, 0.5655, 0.5672, 0.5682, 0.5703, 0.5715, 0.5716, 0.5737, 0.5743, 0.5746, 0.5751, 0.5779, 0.5781, 0.5783, 0.5785, 0.5786, 0.5791, 0.58, 0.5805, 0.5817, 0.5821, 0.583, 0.5843, 0.5846, 0.585, 0.5852, 0.5854, 0.5855, 0.5858, 0.5864, 0.5868, 0.5875, 0.5879, 0.5891, 0.5892, 0.5896, 0.5907, 0.5932, 0.5946, 0.5951, 0.5958, 0.5966, 0.5982, 0.5993, 0.5995, 0.6004, 0.6013, 0.6019, 0.6033, 0.6039, 0.6042, 0.6053, 0.6056, 0.6061, 0.6072, 0.6081, 0.6098, 0.6106, 0.6107, 0.6108, 0.611, 0.6113, 0.6121, 0.6139, 0.6159, 0.6162, 0.6173, 0.6175, 0.6179, 0.6184, 0.6186, 0.6188, 0.6199, 0.6202, 0.6216, 0.6222, 0.6234, 0.6235, 0.6246, 0.6261, 0.6267, 0.627, 0.629, 0.6309, 0.6314, 0.6319, 0.6349, 0.6362, 0.6383, 0.6392, 0.6396, 0.6409, 0.6411, 0.6415, 0.6419, 0.6422, 0.6424, 0.6425, 0.643, 0.6441, 0.6456, 0.6459, 0.6472, 0.6474, 0.6476, 0.649, 0.6496, 0.6507, 0.6517, 0.652, 0.6527, 0.6531, 0.6532, 0.6533, 0.6536, 0.6544, 0.6549, 0.6555, 0.6559999999999999, 0.6564, 0.657, 0.6571, 0.6573, 0.6585, 0.6597, 0.6609, 0.6627, 0.6629999999999999, 0.6651, 0.6652, 0.6656, 0.6659999999999999, 0.6696, 0.6706, 0.6731, 0.6734, 0.6735, 0.6746, 0.6761, 0.6768, 0.6774, 0.6777, 0.6778, 0.6782, 0.6787, 0.6796, 0.6802, 0.6804, 0.6809999999999999, 0.6826, 0.6848, 0.6861, 0.6863, 0.6864, 0.6866, 0.688, 0.6881, 0.6885, 0.6897, 0.6904, 0.6906, 0.6920000000000001, 0.6926, 0.6931, 0.6940000000000001, 0.6942, 0.6943, 0.6946, 0.6947, 0.6953, 0.6955, 0.6963, 0.6970000000000001, 0.6975, 0.6977, 0.6984, 0.6993, 0.6995, 0.7011, 0.7016, 0.7020000000000001, 0.7024, 0.7029, 0.703, 0.7032, 0.7043, 0.7045, 0.7046, 0.7048, 0.7056, 0.7063, 0.7065, 0.7066, 0.7077, 0.7092, 0.7094, 0.71, 0.7101, 0.7108, 0.711, 0.7122, 0.7129, 0.7136, 0.7137, 0.7156, 0.7162, 0.7179, 0.7188, 0.7202, 0.7208, 0.7234, 0.7245, 0.7247, 0.7254, 0.7255, 0.7256, 0.7261, 0.7267, 0.7269, 0.7278, 0.7283, 0.7299, 0.731, 0.7314, 0.7315, 0.7316, 0.7318, 0.733, 0.7332, 0.7341, 0.7358, 0.7369, 0.737, 0.7391, 0.7403, 0.7408, 0.7411, 0.742, 0.7422, 0.7437, 0.7451, 0.7458, 0.746, 0.7463, 0.747, 0.7479, 0.7483, 0.7484, 0.7486, 0.7518, 0.7526, 0.7529, 0.7532, 0.7536, 0.7548, 0.7576, 0.7577, 0.7591, 0.7593, 0.7616, 0.7627, 0.7637, 0.7639, 0.7642, 0.7652, 0.7664, 0.7665, 0.7678, 0.7697, 0.77, 0.7708, 0.772, 0.7725, 0.7727, 0.7734, 0.7737, 0.7751, 0.7759, 0.7762, 0.7776, 0.7787, 0.7788, 0.7802, 0.7808, 0.7812, 0.7826, 0.7831, 0.7849, 0.7867, 0.7884, 0.7892, 0.7895, 0.7904, 0.7925, 0.7935, 0.7939, 0.7946, 0.7949, 0.7965, 0.7987, 0.8002, 0.8003, 0.8006, 0.8026, 0.8035, 0.8044, 0.8049, 0.8052, 0.8056, 0.8059, 0.8067, 0.8068, 0.8072, 0.8074, 0.8089, 0.8096, 0.8099, 0.812, 0.8121, 0.8123, 0.8128, 0.813, 0.8132, 0.8136, 0.8138, 0.8142, 0.815, 0.8155, 0.8174, 0.8176, 0.8181, 0.8188, 0.8193, 0.8202, 0.8208, 0.8223, 0.8229, 0.8237, 0.8252, 0.8254, 0.8262, 0.8271, 0.8282, 0.8284, 0.8288, 0.8294, 0.8301, 0.831, 0.8314, 0.8344, 0.8347, 0.8354, 0.8364, 0.8381, 0.8385, 0.8387, 0.8392, 0.8413, 0.8414, 0.8421, 0.8429, 0.8440000000000001, 0.8452, 0.8454, 0.8455, 0.8458, 0.8462, 0.8491, 0.8519, 0.8521, 0.8525, 0.8527, 0.8541, 0.8547, 0.8554, 0.8563, 0.8564, 0.8585, 0.8614, 0.8626, 0.8632, 0.8634, 0.8657, 0.868, 0.8718, 0.8746, 0.8774, 0.8815, 0.882, 0.8839, 0.8865, 0.8866, 0.8867, 0.8877, 0.8897, 0.8902, 0.8909, 0.892, 0.8923, 0.8936, 0.8959999999999999, 0.8968, 0.8975, 0.8981, 0.9022, 0.9029, 0.9075, 0.9077, 0.9079999999999999, 0.91, 0.9118, 0.9134, 0.9141, 0.9181, 0.9184, 0.9215, 0.9216, 0.9221, 0.9245, 0.9276, 0.9289, 0.9296, 0.9299, 0.9328, 0.9348, 0.9382, 0.9429, 0.9436, 0.9464, 0.9539, 0.956, 0.9570000000000001, 0.9574, 0.9579, 0.9589, 0.9597, 0.9605, 0.9617, 0.9663, 0.9685, 0.9731, 0.9732, 0.9737, 0.9754, 0.9764, 0.9783, 0.9804, 0.9818, 0.9841, 0.9865, 0.9869, 0.9874, 0.9884, 0.9897, 0.9962]\n",
      "\n",
      "Something went wrong. Sleeping 5 seconds.\n",
      "0 Classifiers [00:17, ? Classifiers/s]\n",
      "Error testing classifier: datarun=<ID = 8, dataset ID = 9, strategy = uniform___uniform, budget = walltime (1), status: running>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/worker.py\", line 399, in run_classifier\n",
      "    model, metrics = self.test_classifier(hyperpartition.method, params)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/worker.py\", line 207, in test_classifier\n",
      "    metrics = model.train_test(self.dataset)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/classifier.py\", line 210, in train_test\n",
      "    X_test, y_test = self.encoder.transform(test_data)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/encoder.py\", line 72, in transform\n",
      "    y = self.label_encoder.transform(labels)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 257, in transform\n",
      "    _, y = _encode(y, uniques=self.classes_, encode=True)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 110, in _encode\n",
      "    return _encode_numpy(values, uniques, encode)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 49, in _encode_numpy\n",
      "    % str(diff))\n",
      "ValueError: y contains previously unseen labels: [0.0039, 0.0162, 0.019, 0.0292, 0.0476, 0.0484, 0.057999999999999996, 0.0674, 0.075, 0.0811, 0.0831, 0.0833, 0.0844, 0.0863, 0.0892, 0.0911, 0.0924, 0.0958, 0.0959, 0.0983, 0.1026, 0.1035, 0.10400000000000001, 0.1059, 0.1061, 0.1062, 0.1112, 0.1129, 0.1143, 0.1164, 0.1165, 0.1166, 0.1188, 0.1192, 0.1202, 0.1224, 0.127, 0.1311, 0.1313, 0.1314, 0.1324, 0.1343, 0.1351, 0.1364, 0.1371, 0.1375, 0.1376, 0.1401, 0.1423, 0.1426, 0.14400000000000002, 0.1458, 0.1462, 0.1473, 0.1497, 0.1502, 0.152, 0.1537, 0.1555, 0.1556, 0.1565, 0.1566, 0.1575, 0.1585, 0.1589, 0.16, 0.1611, 0.1613, 0.1627, 0.1633, 0.16399999999999998, 0.1641, 0.1642, 0.166, 0.1673, 0.1706, 0.1718, 0.175, 0.1759, 0.1765, 0.1773, 0.1782, 0.1795, 0.1808, 0.1825, 0.1842, 0.1851, 0.1861, 0.1864, 0.1869, 0.1889, 0.1925, 0.1926, 0.1937, 0.1938, 0.1941, 0.1947, 0.1951, 0.1957, 0.1961, 0.19699999999999998, 0.1977, 0.1987, 0.1991, 0.203, 0.2034, 0.2035, 0.2043, 0.2067, 0.2076, 0.2078, 0.2083, 0.2098, 0.21600000000000005, 0.2162, 0.2183, 0.2184, 0.2189, 0.2191, 0.2196, 0.2199, 0.2218, 0.2222, 0.223, 0.22399999999999998, 0.225, 0.2254, 0.226, 0.2263, 0.2267, 0.2268, 0.2272, 0.2273, 0.2276, 0.2298, 0.2306, 0.2339, 0.23600000000000002, 0.2369, 0.2373, 0.2377, 0.23800000000000002, 0.2383, 0.2386, 0.2397, 0.2399, 0.2413, 0.2414, 0.2422, 0.2427, 0.2469, 0.2474, 0.2477, 0.2478, 0.2481, 0.2508, 0.2531, 0.2535, 0.2555, 0.256, 0.2565, 0.2568, 0.2571, 0.2572, 0.2583, 0.2585, 0.2587, 0.2589, 0.2594, 0.26, 0.2605, 0.2616, 0.2622, 0.2649, 0.2661, 0.2663, 0.2665, 0.2666, 0.2672, 0.2676, 0.2678, 0.2692, 0.2703, 0.273, 0.2744, 0.2754, 0.2759, 0.2772, 0.2774, 0.2785, 0.2801, 0.28300000000000003, 0.284, 0.2862, 0.2864, 0.2867, 0.2878, 0.2884, 0.2893, 0.2902, 0.2907, 0.2922, 0.2923, 0.2944, 0.2945, 0.2957, 0.2994, 0.2995, 0.3002, 0.3015, 0.3019, 0.3022, 0.3024, 0.3026, 0.305, 0.3051, 0.3069, 0.3074, 0.3078, 0.3093, 0.3099, 0.3117, 0.3125, 0.3127, 0.3129, 0.3164, 0.3176, 0.3177, 0.3178, 0.3192, 0.3202, 0.3204, 0.3209, 0.3213, 0.3216, 0.3218, 0.3235, 0.3237, 0.3241, 0.3254, 0.326, 0.3263, 0.3264, 0.3273, 0.3279, 0.32899999999999996, 0.3292, 0.3307, 0.3331, 0.3334, 0.3335, 0.3344, 0.3349, 0.3357, 0.3363, 0.3373, 0.3379, 0.33799999999999997, 0.3393, 0.3405, 0.3411, 0.3419, 0.3422, 0.3424, 0.3426, 0.3427, 0.3436, 0.3452, 0.3455, 0.3461, 0.34700000000000003, 0.3472, 0.3476, 0.3483, 0.349, 0.3504, 0.3518, 0.3534, 0.3535, 0.3541, 0.3542, 0.3545, 0.3546, 0.3559, 0.3561, 0.3585, 0.3598, 0.3613, 0.3621, 0.3627, 0.3639, 0.366, 0.3668, 0.3675, 0.3692, 0.3701, 0.3702, 0.3706, 0.3711, 0.3713, 0.3719, 0.373, 0.375, 0.3753, 0.3758, 0.3764, 0.3768, 0.377, 0.3772, 0.3782, 0.3785, 0.3804, 0.3813, 0.3845, 0.3849, 0.3856, 0.3858, 0.3873, 0.3874, 0.38799999999999996, 0.3888, 0.3892, 0.3894, 0.3895, 0.3906, 0.3908, 0.3927, 0.3929, 0.39299999999999996, 0.3936, 0.3957, 0.3978, 0.3981, 0.3993, 0.3998, 0.4006, 0.4007, 0.4011, 0.4018, 0.4023, 0.4026, 0.4027, 0.4038, 0.4039, 0.4046, 0.4047, 0.4051, 0.4053, 0.4064, 0.4069, 0.4082, 0.4091, 0.4106, 0.4121, 0.4132, 0.4149, 0.4163, 0.4175, 0.4178, 0.4184, 0.4186, 0.4189, 0.4193, 0.4203, 0.4211, 0.42200000000000004, 0.4222, 0.4233, 0.4241, 0.4264, 0.4267, 0.431, 0.4318, 0.4327, 0.4328, 0.4341, 0.4343, 0.4347, 0.436, 0.4375, 0.4391, 0.4392, 0.4395, 0.4399, 0.4405, 0.4418, 0.442, 0.4431, 0.4433, 0.4434, 0.4438, 0.444, 0.4449, 0.4452, 0.4463, 0.4466, 0.447, 0.4482, 0.4487, 0.4488, 0.4491, 0.4496, 0.4503, 0.4514, 0.4517, 0.4523, 0.4537, 0.4555, 0.4556, 0.4562, 0.4564, 0.4578, 0.4584, 0.4589, 0.4592, 0.4599, 0.4601, 0.4608, 0.4609, 0.4619, 0.4625, 0.46299999999999997, 0.4638, 0.465, 0.4656, 0.4674, 0.4678, 0.4682, 0.4697, 0.4704, 0.4709, 0.47100000000000003, 0.4718, 0.4719, 0.4721, 0.4726, 0.4752, 0.4758, 0.4772, 0.4796, 0.4821, 0.4826, 0.4831, 0.4834, 0.4852, 0.4854, 0.4857, 0.4863, 0.48700000000000004, 0.4876, 0.4882, 0.4896, 0.4909, 0.4958, 0.4967, 0.4978, 0.4985, 0.4992, 0.5005, 0.5006, 0.5018, 0.5027, 0.5032, 0.505, 0.5069, 0.5083, 0.5086, 0.5093, 0.5108, 0.5115, 0.5121, 0.5126, 0.5131, 0.5135, 0.5137, 0.5142, 0.5156, 0.5159, 0.5162, 0.5167, 0.5192, 0.5196, 0.5197, 0.5202, 0.5206, 0.5211, 0.5216, 0.5218, 0.5224, 0.5231, 0.5238, 0.5251, 0.5279, 0.5287, 0.53, 0.5302, 0.5308, 0.5313, 0.5325, 0.5334, 0.5337, 0.5339, 0.5347, 0.5351, 0.5353, 0.5356, 0.5373, 0.5383, 0.5391, 0.5396, 0.5401, 0.5406, 0.5407, 0.5409, 0.5414, 0.5417, 0.542, 0.5421, 0.5441, 0.5473, 0.5476, 0.5483, 0.5487, 0.5526, 0.5529, 0.5536, 0.5565, 0.5571, 0.5572, 0.5582, 0.5583, 0.5588, 0.5589999999999999, 0.5591, 0.5594, 0.561, 0.5616, 0.5653, 0.5655, 0.5671, 0.5677, 0.5711, 0.5715, 0.5716, 0.5720000000000001, 0.5724, 0.5732, 0.5733, 0.5739, 0.5741, 0.5744, 0.5746, 0.5748, 0.5751, 0.5774, 0.5786, 0.5791, 0.5793, 0.58, 0.5819, 0.583, 0.5831, 0.5852, 0.5861, 0.5868, 0.5874, 0.5878, 0.5886, 0.5889, 0.5897, 0.5931, 0.594, 0.5944, 0.5945, 0.5977, 0.5995, 0.6007, 0.6008, 0.6019, 0.6028, 0.604, 0.6043, 0.6045, 0.6049, 0.6058, 0.606, 0.6072, 0.6093, 0.6097, 0.6098, 0.6104, 0.6105, 0.6108, 0.611, 0.6119, 0.6134, 0.6135, 0.6145, 0.6147, 0.6164, 0.6178, 0.6186, 0.6201, 0.6224, 0.6231, 0.6233, 0.6246, 0.6248, 0.6256, 0.626, 0.627, 0.6297, 0.6298, 0.63, 0.631, 0.6314, 0.6319, 0.6324, 0.633, 0.6351, 0.6357, 0.6359, 0.6362, 0.6383, 0.6389, 0.6396, 0.6403, 0.6405, 0.6411, 0.6417, 0.6419, 0.6422, 0.6424, 0.6443, 0.6459, 0.6496, 0.6504, 0.6506, 0.6507, 0.6514, 0.6527, 0.6546, 0.6549, 0.6564, 0.6572, 0.6573, 0.6578, 0.6579, 0.6579999999999999, 0.6589, 0.6597, 0.6601, 0.6622, 0.6649, 0.6662, 0.6671, 0.6677, 0.6706, 0.6714, 0.6715, 0.6716, 0.672, 0.6722, 0.6727, 0.6731, 0.6734, 0.6735, 0.6736, 0.6755, 0.6759, 0.6759999999999999, 0.677, 0.6778, 0.6781, 0.6791, 0.68, 0.6809999999999999, 0.6826, 0.6827, 0.6875, 0.688, 0.6881, 0.6897, 0.6904, 0.6931, 0.6933, 0.6963, 0.6967, 0.6981, 0.6995, 0.6996, 0.6999, 0.7011, 0.7016, 0.7021, 0.7023, 0.7024, 0.7025, 0.7029, 0.703, 0.7033, 0.7040000000000001, 0.7043, 0.7044, 0.7046, 0.7048, 0.7049, 0.7068, 0.7071, 0.7094, 0.7101, 0.7102, 0.7108, 0.7109, 0.711, 0.7111, 0.7116, 0.7121, 0.7123, 0.7129, 0.7137, 0.7158, 0.7185, 0.7204, 0.7215, 0.7245, 0.7247, 0.7255, 0.7267, 0.7271, 0.7278, 0.7284, 0.7287, 0.7297, 0.7303, 0.7304, 0.7307, 0.7309, 0.731, 0.7316, 0.7332, 0.7348, 0.7351, 0.7355, 0.7358, 0.7373, 0.7386, 0.7393, 0.7406, 0.7422, 0.7427, 0.7432, 0.7442, 0.7444, 0.7451, 0.7454, 0.7463, 0.7473, 0.7486, 0.7506, 0.752, 0.7526, 0.7536, 0.7558, 0.7593, 0.7608, 0.7627, 0.7632, 0.7639, 0.7647, 0.7649, 0.7656, 0.7659999999999999, 0.7665, 0.7678, 0.768, 0.7704, 0.7706, 0.7725, 0.7734, 0.7745, 0.7754, 0.7762, 0.7771, 0.7781, 0.7788, 0.7804, 0.7806, 0.7812, 0.7817, 0.7822, 0.7831, 0.7833, 0.7845, 0.7846, 0.7853, 0.7859, 0.7886, 0.7893, 0.7908, 0.7917, 0.7931, 0.7939, 0.7944, 0.7945, 0.7946, 0.7969, 0.7972, 0.7987, 0.7991, 0.8003, 0.8006, 0.8008, 0.8018, 0.8049, 0.8053, 0.8054, 0.8059, 0.8084, 0.8107, 0.8113, 0.8121, 0.8123, 0.8128, 0.8132, 0.8137, 0.8142, 0.815, 0.8156, 0.8162, 0.8171, 0.8194, 0.8204, 0.8223, 0.8231, 0.8244, 0.8255, 0.8258, 0.8266, 0.8284, 0.8288, 0.8294, 0.8314, 0.8316, 0.8338, 0.8346, 0.8387, 0.841, 0.8413, 0.8414, 0.8429, 0.8431, 0.8440000000000001, 0.8462, 0.8467, 0.8476, 0.8477, 0.848, 0.8481, 0.8499, 0.8504, 0.8513, 0.8518, 0.8532, 0.8533, 0.8553, 0.8563, 0.8579, 0.858, 0.8581, 0.8582, 0.8585, 0.8597, 0.861, 0.8616, 0.8631, 0.8632, 0.8642, 0.8652, 0.8662, 0.8705, 0.8707, 0.872, 0.8737, 0.8742, 0.8745, 0.8746, 0.8801, 0.8811, 0.8827, 0.8828, 0.8829, 0.8866, 0.8868, 0.8897, 0.8902, 0.8909, 0.8914, 0.892, 0.8923, 0.8959999999999999, 0.8994, 0.9062, 0.9064, 0.9067, 0.9079999999999999, 0.9118, 0.9127, 0.9138, 0.9157, 0.9175, 0.9176, 0.9205, 0.9223, 0.9245, 0.9296, 0.93, 0.9318, 0.9322, 0.9323, 0.9328, 0.9348, 0.9379, 0.9421, 0.9436, 0.9497, 0.9498, 0.9538, 0.9539, 0.9579, 0.9605, 0.9617, 0.9634, 0.965, 0.9675, 0.9735, 0.9737, 0.9741, 0.9754, 0.9784, 0.9791, 0.9798, 0.9804, 0.9808, 0.9841, 0.9851, 0.9855, 0.9865, 0.9878, 0.9884, 0.9888, 0.9897, 0.9901, 0.9938, 0.9962, 0.9975]\n",
      "\n",
      "Something went wrong. Sleeping 5 seconds.\n",
      "\n",
      "0 Classifiers [00:15, ? Classifiers/s]\u001b[A\n",
      "Error testing classifier: datarun=<ID = 8, dataset ID = 9, strategy = uniform___uniform, budget = walltime (1), status: running>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/worker.py\", line 399, in run_classifier\n",
      "    model, metrics = self.test_classifier(hyperpartition.method, params)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/worker.py\", line 207, in test_classifier\n",
      "    metrics = model.train_test(self.dataset)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/classifier.py\", line 210, in train_test\n",
      "    X_test, y_test = self.encoder.transform(test_data)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/encoder.py\", line 72, in transform\n",
      "    y = self.label_encoder.transform(labels)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 257, in transform\n",
      "    _, y = _encode(y, uniques=self.classes_, encode=True)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 110, in _encode\n",
      "    return _encode_numpy(values, uniques, encode)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 49, in _encode_numpy\n",
      "    % str(diff))\n",
      "ValueError: y contains previously unseen labels: [0.0162, 0.019, 0.0272, 0.0313, 0.0484, 0.054000000000000006, 0.0606, 0.0608, 0.0638, 0.0674, 0.069, 0.0755, 0.0758, 0.0769, 0.0779, 0.0823, 0.0862, 0.0911, 0.0924, 0.0947, 0.0959, 0.1007, 0.10099999999999999, 0.1016, 0.1063, 0.1067, 0.1111, 0.1156, 0.1164, 0.1166, 0.1167, 0.1169, 0.1178, 0.1205, 0.1232, 0.127, 0.1311, 0.1313, 0.1324, 0.1341, 0.1343, 0.1351, 0.1357, 0.1371, 0.1401, 0.1404, 0.1417, 0.1424, 0.14400000000000002, 0.1462, 0.1463, 0.1473, 0.1507, 0.1508, 0.1521, 0.1528, 0.1549, 0.1553, 0.1554, 0.1555, 0.1556, 0.156, 0.1575, 0.1585, 0.1589, 0.1611, 0.1613, 0.1637, 0.1642, 0.1673, 0.168, 0.1719, 0.1736, 0.174, 0.1744, 0.1745, 0.1752, 0.1754, 0.1765, 0.1782, 0.1832, 0.1844, 0.1847, 0.1852, 0.1856, 0.18600000000000005, 0.1861, 0.1869, 0.1899, 0.1903, 0.1925, 0.1938, 0.1947, 0.1948, 0.1959, 0.1978, 0.1998, 0.2011, 0.2021, 0.203, 0.2032, 0.204, 0.2045, 0.2055, 0.2058, 0.2088, 0.209, 0.2092, 0.21, 0.2131, 0.2135, 0.2136, 0.2154, 0.2169, 0.2175, 0.2176, 0.2196, 0.2235, 0.2238, 0.2239, 0.22399999999999998, 0.2244, 0.225, 0.226, 0.2263, 0.2267, 0.2268, 0.2311, 0.2318, 0.2338, 0.2342, 0.2376, 0.2388, 0.2401, 0.2429, 0.2431, 0.2457, 0.2466, 0.2469, 0.2481, 0.2486, 0.2513, 0.2526, 0.2533, 0.2535, 0.2553, 0.2566, 0.257, 0.2576, 0.2596, 0.2598, 0.2601, 0.2605, 0.2616, 0.2623, 0.2629, 0.2631, 0.2642, 0.2644, 0.2646, 0.2654, 0.2665, 0.2666, 0.2672, 0.2684, 0.26899999999999996, 0.2691, 0.2695, 0.2697, 0.2699, 0.2703, 0.2737, 0.27399999999999997, 0.275, 0.2754, 0.2757, 0.2762, 0.2766, 0.2769, 0.2787, 0.2791, 0.2792, 0.2798, 0.28300000000000003, 0.2839, 0.284, 0.2842, 0.2846, 0.2854, 0.2864, 0.2868, 0.2878, 0.2881, 0.2888, 0.2889, 0.289, 0.2892, 0.2895, 0.2897, 0.2902, 0.2923, 0.2929, 0.2953, 0.2955, 0.29600000000000004, 0.2963, 0.2969, 0.2983, 0.2995, 0.3021, 0.3026, 0.3028, 0.3047, 0.3051, 0.3057, 0.3068, 0.3074, 0.3076, 0.3079, 0.3081, 0.3083, 0.3087, 0.3091, 0.3092, 0.3095, 0.3099, 0.3104, 0.3111, 0.3117, 0.316, 0.3169, 0.3187, 0.319, 0.3195, 0.3196, 0.3202, 0.3203, 0.3213, 0.3234, 0.3247, 0.3248, 0.325, 0.3257, 0.3268, 0.3282, 0.3286, 0.32899999999999996, 0.3292, 0.3305, 0.3314, 0.3317, 0.3321, 0.3322, 0.3334, 0.3352, 0.3368, 0.3373, 0.33799999999999997, 0.3399, 0.3422, 0.3423, 0.3427, 0.344, 0.3458, 0.3463, 0.3467, 0.3472, 0.3483, 0.349, 0.3497, 0.3498, 0.3504, 0.3541, 0.3545, 0.3548, 0.3552, 0.3555, 0.3559, 0.3562, 0.3578, 0.3582, 0.3592, 0.3602, 0.3611, 0.3613, 0.3615, 0.3621, 0.3625, 0.363, 0.3631, 0.364, 0.3649, 0.3653, 0.3684, 0.3688, 0.3692, 0.3699, 0.3713, 0.3738, 0.3739, 0.3746, 0.3747, 0.3758, 0.3762, 0.3765, 0.3782, 0.3791, 0.3796, 0.3805, 0.3808, 0.3818, 0.3825, 0.3838, 0.3844, 0.3849, 0.3852, 0.3869, 0.3892, 0.3898, 0.3901, 0.3918, 0.3921, 0.3923, 0.39299999999999996, 0.3948, 0.3953, 0.3956, 0.396, 0.3969, 0.3999, 0.4006, 0.4017, 0.402, 0.4021, 0.4023, 0.4026, 0.4029, 0.4038, 0.40399999999999997, 0.4046, 0.4047, 0.4067, 0.4081, 0.4084, 0.4091, 0.4099, 0.4111, 0.4139, 0.4148, 0.4149, 0.4153, 0.4154, 0.4155, 0.4209, 0.4216, 0.4248, 0.4267, 0.4273, 0.4276, 0.4279, 0.4281, 0.4293, 0.4322, 0.4327, 0.4333, 0.4343, 0.4346, 0.4355, 0.436, 0.4371, 0.4375, 0.4386, 0.4391, 0.4394, 0.4396, 0.441, 0.4413, 0.4418, 0.4423, 0.4433, 0.4439, 0.444, 0.4449, 0.445, 0.4451, 0.4458, 0.447, 0.4472, 0.4487, 0.4494, 0.4497, 0.4503, 0.4517, 0.4539, 0.4542, 0.4543, 0.4547, 0.4554, 0.4562, 0.4573, 0.4591, 0.4592, 0.4594, 0.4612, 0.4616, 0.4621, 0.46399999999999997, 0.4653, 0.4666, 0.4671, 0.4672, 0.4693, 0.4694, 0.4697, 0.4698, 0.4704, 0.4707, 0.4711, 0.4722, 0.4726, 0.4741, 0.4784, 0.4785, 0.4788, 0.4789, 0.4802, 0.4809, 0.4814, 0.4815, 0.4819, 0.48200000000000004, 0.4838, 0.4841, 0.4848, 0.4852, 0.4876, 0.4878, 0.4879, 0.4882, 0.4884, 0.4896, 0.4909, 0.4918, 0.4926, 0.4937, 0.4957, 0.4978, 0.4984, 0.5005, 0.501, 0.5027, 0.5066, 0.5071, 0.5076, 0.5079, 0.5086, 0.5096, 0.51, 0.5115, 0.5121, 0.5128, 0.5131, 0.5135, 0.5137, 0.5142, 0.5167, 0.5191, 0.5197, 0.5203, 0.5209, 0.521, 0.5216, 0.5232, 0.5242, 0.5245, 0.5279, 0.5286, 0.5298, 0.5299, 0.53, 0.5301, 0.5325, 0.5334, 0.5336, 0.5342, 0.5371, 0.5373, 0.5392, 0.5394, 0.5401, 0.5404, 0.5409, 0.542, 0.5421, 0.5439, 0.5456, 0.5458, 0.5462, 0.5481, 0.5482, 0.5483, 0.5489999999999999, 0.5507, 0.551, 0.5511, 0.5512, 0.5527, 0.5537, 0.5544, 0.5545, 0.5563, 0.5566, 0.5573, 0.5589999999999999, 0.5597, 0.5603, 0.5607, 0.5608, 0.5612, 0.5632, 0.5642, 0.5646, 0.5653, 0.5664, 0.5667, 0.5677, 0.5682, 0.5684, 0.5697, 0.5711, 0.5721, 0.5738, 0.5739, 0.5743, 0.5744, 0.5746, 0.5748, 0.5765, 0.5771, 0.5778, 0.5779, 0.5786, 0.5791, 0.5806, 0.5825, 0.583, 0.5831, 0.584, 0.5843, 0.5848, 0.5852, 0.5854, 0.5855, 0.5859, 0.5879, 0.5892, 0.5901, 0.5912, 0.5917, 0.593, 0.5945, 0.5958, 0.5963, 0.5986, 0.6008, 0.6033, 0.6055, 0.6056, 0.6063, 0.6068, 0.6093, 0.6107, 0.6116, 0.6123, 0.6134, 0.6144, 0.6159, 0.6162, 0.6169, 0.617, 0.6179, 0.6186, 0.6188, 0.6191, 0.6203, 0.6214, 0.6217, 0.6222, 0.6224, 0.6227, 0.6233, 0.6238, 0.6246, 0.6263, 0.6273, 0.6286, 0.6297, 0.6304, 0.6319, 0.632, 0.6324, 0.6349, 0.6357, 0.637, 0.6389, 0.6392, 0.6403, 0.6408, 0.6417, 0.6419, 0.6424, 0.643, 0.6458, 0.6459, 0.6472, 0.649, 0.6505, 0.6508, 0.6514, 0.6515, 0.652, 0.6529, 0.6533, 0.6535, 0.6539, 0.6546, 0.6548, 0.6555, 0.6559, 0.6561, 0.6571, 0.6572, 0.6573, 0.6575, 0.6579, 0.6599, 0.6614, 0.6627, 0.6629, 0.6634, 0.6636, 0.6648, 0.6652, 0.6703, 0.6709, 0.6714, 0.6731, 0.6735, 0.6736, 0.6751, 0.6759, 0.6774, 0.6778, 0.6786, 0.6787, 0.6797, 0.6798, 0.6859, 0.6863, 0.6864, 0.6872, 0.688, 0.6881, 0.6885, 0.6890000000000001, 0.6897, 0.6899, 0.69, 0.6906, 0.6908, 0.6926, 0.6933, 0.6938, 0.6967, 0.6977, 0.698, 0.6981, 0.6982, 0.6999, 0.7021, 0.7029, 0.7041, 0.7043, 0.7046, 0.7047, 0.7058, 0.7062, 0.7066, 0.7067, 0.7068, 0.7072, 0.7082, 0.7087, 0.7104, 0.7113, 0.7120000000000001, 0.7123, 0.7132, 0.7137, 0.7156, 0.7158, 0.7163, 0.7170000000000001, 0.7184, 0.7185, 0.7187, 0.7188, 0.7191, 0.7194, 0.7201, 0.7209, 0.722, 0.7226, 0.7234, 0.7245, 0.7254, 0.7261, 0.7271, 0.7275, 0.7278, 0.7296, 0.7308, 0.7309, 0.7315, 0.7331, 0.7347, 0.7376, 0.7379, 0.7391, 0.7406, 0.7408, 0.7427, 0.7431, 0.7462, 0.7463, 0.7473, 0.7479, 0.7486, 0.7489, 0.7490000000000001, 0.7502, 0.7503, 0.7525, 0.7526, 0.7548, 0.755, 0.7551, 0.7556, 0.7557, 0.7558, 0.7565, 0.7569, 0.7576, 0.7579, 0.7589, 0.7593, 0.7596, 0.7605, 0.7606, 0.7624, 0.7628, 0.7637, 0.7653, 0.7677, 0.7678, 0.7694, 0.7727, 0.7754, 0.7773, 0.7784, 0.7788, 0.7806, 0.7812, 0.7817, 0.7831, 0.784, 0.7844, 0.7871, 0.7884, 0.7892, 0.7893, 0.7901, 0.7929999999999999, 0.7931, 0.7935, 0.7937, 0.7948, 0.7949, 0.7951, 0.7973, 0.7979, 0.8008, 0.8011, 0.8013, 0.8026, 0.8035, 0.8037, 0.804, 0.8049, 0.8063, 0.8067, 0.8068, 0.807, 0.8082, 0.8083, 0.8089, 0.8098, 0.8106, 0.8109999999999999, 0.8119, 0.8121, 0.8122, 0.8123, 0.8125, 0.8138, 0.8141, 0.815, 0.8151, 0.8171, 0.8175, 0.8176, 0.8195, 0.8204, 0.8207, 0.8224, 0.8244, 0.8258, 0.8273, 0.8284, 0.8294, 0.8320000000000001, 0.8338, 0.8341, 0.8346, 0.8348, 0.8373, 0.8379, 0.8387, 0.8392, 0.8395, 0.8399, 0.8428, 0.8429, 0.8431, 0.8433, 0.8458, 0.8467, 0.8477, 0.8497, 0.8498, 0.8513, 0.8516, 0.8518, 0.8521, 0.8525, 0.8527, 0.8549, 0.8563, 0.8564, 0.8581, 0.8604, 0.8641, 0.8642, 0.8649, 0.8652, 0.8657, 0.8659, 0.8669, 0.8705, 0.8707, 0.8718, 0.8731, 0.8742, 0.8764, 0.8772, 0.8792, 0.882, 0.8827, 0.8839, 0.8865, 0.8866, 0.8877, 0.8884, 0.8897, 0.8914, 0.8923, 0.8943, 0.8944, 0.8969, 0.897, 0.9014, 0.9029, 0.9063, 0.9067, 0.9075, 0.9077, 0.9079999999999999, 0.9093, 0.9098, 0.91, 0.9106, 0.9118, 0.9132, 0.9134, 0.9138, 0.9141, 0.9151, 0.9157, 0.9176, 0.9184, 0.9194, 0.9219, 0.9221, 0.9236, 0.9245, 0.9265, 0.9276, 0.9277, 0.9294, 0.9302, 0.9309999999999999, 0.9372, 0.9414, 0.9421, 0.9423, 0.9429, 0.9436, 0.9470000000000001, 0.9498, 0.9597, 0.9605, 0.9631, 0.9635, 0.9670000000000001, 0.9701, 0.9764, 0.978, 0.9784, 0.9791, 0.9818, 0.9822, 0.9834, 0.9851, 0.9869, 0.9901, 0.9962, 0.9975]\n",
      "\n",
      "Something went wrong. Sleeping 5 seconds.\n",
      "0 Classifiers [00:15, ? Classifiers/s]\n",
      "Error testing classifier: datarun=<ID = 8, dataset ID = 9, strategy = uniform___uniform, budget = walltime (1), status: running>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/worker.py\", line 399, in run_classifier\n",
      "    model, metrics = self.test_classifier(hyperpartition.method, params)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/worker.py\", line 207, in test_classifier\n",
      "    metrics = model.train_test(self.dataset)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/classifier.py\", line 210, in train_test\n",
      "    X_test, y_test = self.encoder.transform(test_data)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/atm/encoder.py\", line 72, in transform\n",
      "    y = self.label_encoder.transform(labels)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 257, in transform\n",
      "    _, y = _encode(y, uniques=self.classes_, encode=True)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 110, in _encode\n",
      "    return _encode_numpy(values, uniques, encode)\n",
      "  File \"/Users/gerritscheeppat/anaconda3/envs/atm/lib/python3.6/site-packages/sklearn/preprocessing/label.py\", line 49, in _encode_numpy\n",
      "    % str(diff))\n",
      "ValueError: y contains previously unseen labels: [0.0049, 0.0162, 0.019, 0.0248, 0.0292, 0.0382, 0.0535, 0.054000000000000006, 0.0617, 0.0638, 0.0674, 0.0811, 0.0831, 0.0862, 0.087, 0.0892, 0.0924, 0.0947, 0.0962, 0.1067, 0.1148, 0.1154, 0.1178, 0.1197, 0.12, 0.1215, 0.1224, 0.1288, 0.1311, 0.1333, 0.1343, 0.1344, 0.1357, 0.1376, 0.1404, 0.1415, 0.1419, 0.1423, 0.1426, 0.1441, 0.146, 0.1463, 0.1488, 0.1494, 0.1514, 0.1521, 0.1528, 0.1531, 0.1555, 0.1556, 0.1565, 0.1566, 0.1577, 0.1589, 0.1613, 0.1637, 0.1641, 0.1642, 0.1673, 0.168, 0.1702, 0.1719, 0.1721, 0.1725, 0.1736, 0.1745, 0.1748, 0.175, 0.1763, 0.1768, 0.1782, 0.18, 0.1808, 0.1813, 0.1834, 0.1839, 0.1842, 0.1847, 0.1851, 0.1855, 0.18600000000000005, 0.1861, 0.1872, 0.1878, 0.1904, 0.1906, 0.1907, 0.1926, 0.1941, 0.1948, 0.1957, 0.1959, 0.1973, 0.1978, 0.1998, 0.2003, 0.2008, 0.2011, 0.2021, 0.203, 0.2034, 0.2042, 0.209, 0.2097, 0.2098, 0.2101, 0.2136, 0.2154, 0.2162, 0.2165, 0.2171, 0.2176, 0.2177, 0.2184, 0.2192, 0.2209, 0.2212, 0.2216, 0.2218, 0.2235, 0.2248, 0.225, 0.2255, 0.2278, 0.2282, 0.2323, 0.2339, 0.2341, 0.2347, 0.2366, 0.2378, 0.2388, 0.2406, 0.2414, 0.2426, 0.2428, 0.2436, 0.245, 0.2462, 0.2492, 0.2531, 0.2533, 0.255, 0.2555, 0.2559, 0.2566, 0.2571, 0.2579, 0.2585, 0.2589, 0.2592, 0.2593, 0.2595, 0.2596, 0.2598, 0.2601, 0.261, 0.2618, 0.2633, 0.2637, 0.2642, 0.2654, 0.2662, 0.267, 0.2672, 0.2676, 0.2695, 0.2698, 0.2699, 0.27, 0.2703, 0.2707, 0.2712, 0.2714, 0.2732, 0.2737, 0.27399999999999997, 0.275, 0.2767, 0.2772, 0.2781, 0.2791, 0.28, 0.2801, 0.2822, 0.2825, 0.28300000000000003, 0.2835, 0.2849, 0.2854, 0.2867, 0.2872, 0.2878, 0.2881, 0.2893, 0.2904, 0.2907, 0.292, 0.2942, 0.2948, 0.2951, 0.2952, 0.2953, 0.2957, 0.2968, 0.2969, 0.2982, 0.2989, 0.2993, 0.2994, 0.2995, 0.2996, 0.3015, 0.3019, 0.3022, 0.3038, 0.305, 0.3054, 0.3057, 0.3066, 0.3074, 0.3081, 0.3087, 0.309, 0.3092, 0.3104, 0.3114, 0.3116, 0.3118, 0.3125, 0.313, 0.3144, 0.3151, 0.3178, 0.3202, 0.3203, 0.3209, 0.3213, 0.3225, 0.3233, 0.3248, 0.3254, 0.3255, 0.3257, 0.3265, 0.3275, 0.3286, 0.3292, 0.3306, 0.3307, 0.3313, 0.3317, 0.3326, 0.3331, 0.33399999999999996, 0.3352, 0.3363, 0.3369, 0.33799999999999997, 0.3384, 0.3405, 0.3416, 0.3423, 0.3435, 0.344, 0.3446, 0.3452, 0.3454, 0.3455, 0.3469, 0.3473, 0.3476, 0.3515, 0.3518, 0.3524, 0.3529, 0.3541, 0.3544, 0.355, 0.3562, 0.35700000000000004, 0.3578, 0.3582, 0.3585, 0.3598, 0.3599, 0.3615, 0.3618, 0.3624, 0.3627, 0.3632, 0.3647, 0.365, 0.3659, 0.3668, 0.3670000000000001, 0.3677, 0.3679, 0.368, 0.3684, 0.3685, 0.3696, 0.3699, 0.3703, 0.3706, 0.3711, 0.3713, 0.3719, 0.3728, 0.3734, 0.3735, 0.374, 0.3745, 0.3753, 0.3756, 0.3784, 0.3791, 0.3805, 0.38299999999999995, 0.3856, 0.3867, 0.3869, 0.3877, 0.3887, 0.3895, 0.3897, 0.3898, 0.39, 0.3909, 0.3916, 0.3918, 0.3925, 0.3928, 0.3929, 0.3939, 0.3941, 0.3944, 0.395, 0.3969, 0.401, 0.4011, 0.4015, 0.4018, 0.4021, 0.4025, 0.40299999999999997, 0.4031, 0.4037, 0.40399999999999997, 0.4046, 0.4047, 0.4053, 0.4061, 0.4064, 0.4067, 0.4085, 0.4091, 0.4121, 0.4124, 0.4134, 0.4144, 0.4146, 0.4147, 0.4173, 0.4178, 0.4189, 0.4193, 0.4199, 0.42, 0.4201, 0.4222, 0.4225, 0.4233, 0.4254, 0.4259, 0.426, 0.4267, 0.4273, 0.4281, 0.4285, 0.4302, 0.4304, 0.4318, 0.4353, 0.436, 0.4365, 0.4371, 0.4376, 0.4387, 0.4389, 0.4405, 0.4412, 0.4413, 0.4418, 0.4438, 0.445, 0.4458, 0.4472, 0.4477, 0.4484, 0.4496, 0.4497, 0.4504, 0.4506, 0.452, 0.4523, 0.4531, 0.4539, 0.4562, 0.4591, 0.4593, 0.4601, 0.4616, 0.4617, 0.4619, 0.462, 0.4628, 0.4637, 0.4638, 0.4655, 0.4664, 0.4678, 0.4681, 0.4694, 0.4697, 0.4707, 0.47100000000000003, 0.4717, 0.4726, 0.4727, 0.4731, 0.474, 0.4741, 0.4749, 0.4758, 0.4775, 0.4777, 0.4779, 0.478, 0.4781, 0.4785, 0.4814, 0.4826, 0.4831, 0.4838, 0.485, 0.4877, 0.4883, 0.4884, 0.4889, 0.49, 0.4929, 0.4934, 0.4937, 0.4958, 0.496, 0.4967, 0.4978, 0.5016, 0.5018, 0.5028, 0.5031, 0.5032, 0.505, 0.5062, 0.5066, 0.507, 0.5072, 0.5074, 0.508, 0.5082, 0.5083, 0.5096, 0.5124, 0.5131, 0.5135, 0.5141, 0.5142, 0.5143, 0.5154, 0.5156, 0.5167, 0.5175, 0.5191, 0.5205, 0.5209, 0.521, 0.5211, 0.5219, 0.5233, 0.5255, 0.5263, 0.5279, 0.5285, 0.53, 0.5302, 0.5317, 0.5325, 0.5327, 0.5354, 0.5356, 0.5382, 0.5383, 0.5385, 0.5396, 0.5412, 0.5441, 0.546, 0.5461, 0.5462, 0.5467, 0.5489999999999999, 0.5506, 0.5507, 0.5512, 0.5529, 0.5531, 0.5537, 0.5544, 0.5563, 0.5576, 0.5591, 0.5594, 0.5597, 0.5607, 0.561, 0.5619, 0.5631, 0.5646, 0.5652, 0.5671, 0.5673, 0.5682, 0.5691, 0.5711, 0.5738, 0.5741, 0.5746, 0.5754, 0.5755, 0.5765, 0.5767, 0.5768, 0.5771, 0.5778, 0.5783, 0.5786, 0.5799, 0.5812, 0.5819, 0.5821, 0.5827, 0.584, 0.5844, 0.5846, 0.5853, 0.5854, 0.5864, 0.5870000000000001, 0.5878, 0.5891, 0.5901, 0.5907, 0.5917, 0.5932, 0.5949, 0.5958, 0.5966, 0.6004, 0.6005, 0.6007, 0.6008, 0.6022, 0.6025, 0.6033, 0.6034, 0.6044, 0.6049, 0.6053, 0.6056, 0.6059, 0.606, 0.6068, 0.6085, 0.6093, 0.6105, 0.6119, 0.612, 0.6121, 0.6134, 0.6179, 0.6183, 0.6203, 0.6217, 0.6218, 0.623, 0.6234, 0.6235, 0.6242, 0.626, 0.6261, 0.6262, 0.6278, 0.6297, 0.6303, 0.6315, 0.6331, 0.6353, 0.6359, 0.6373, 0.6375, 0.6383, 0.6384, 0.6425, 0.643, 0.6443, 0.6445, 0.6451, 0.6457, 0.6458, 0.6459, 0.6472, 0.6476, 0.6488, 0.6497, 0.6504, 0.6505, 0.6512, 0.6514, 0.652, 0.6535, 0.6541, 0.6555, 0.6559, 0.6562, 0.6568, 0.6571, 0.6578, 0.6594, 0.6607, 0.6609, 0.6613, 0.6614, 0.6622, 0.6627, 0.6629999999999999, 0.6638, 0.6648, 0.6649, 0.6669, 0.6709, 0.6716, 0.6727, 0.6768, 0.6775, 0.6777, 0.6778, 0.6786, 0.6793, 0.6811, 0.6821, 0.6826, 0.6831, 0.6836, 0.6839, 0.6859999999999999, 0.6866, 0.6872, 0.6873, 0.6881, 0.6884, 0.6897, 0.6914, 0.6931, 0.6938, 0.6943, 0.6947, 0.6963, 0.6971, 0.6973, 0.6979, 0.6981, 0.6996, 0.7003, 0.7007, 0.7018, 0.7024, 0.7033, 0.7043, 0.7046, 0.7049, 0.7051, 0.7056, 0.7067, 0.7075, 0.7082, 0.7085, 0.7098, 0.71, 0.7101, 0.7107, 0.7115, 0.7116, 0.7122, 0.7126, 0.7148, 0.7153, 0.7162, 0.7166, 0.7176, 0.7179, 0.7183, 0.7185, 0.7205, 0.7215, 0.7237, 0.7243, 0.7253, 0.7256, 0.7259, 0.726, 0.7265, 0.7278, 0.7297, 0.7299, 0.731, 0.7311, 0.7315, 0.7316, 0.7321, 0.7336, 0.7353, 0.7355, 0.7372, 0.7375, 0.7406, 0.741, 0.742, 0.7422, 0.7432, 0.7433, 0.7439, 0.7446, 0.7462, 0.7463, 0.7475, 0.7476, 0.7479, 0.748, 0.7483, 0.7484, 0.7486, 0.7491, 0.7498, 0.7511, 0.7513, 0.7518, 0.752, 0.7521, 0.7525, 0.7527, 0.7529, 0.7531, 0.7532, 0.7557, 0.7565, 0.7569, 0.7579, 0.7596, 0.7605, 0.7606, 0.7607, 0.7608, 0.762, 0.7627, 0.7632, 0.7637, 0.7647, 0.7665, 0.7678, 0.7682, 0.7687, 0.7696, 0.7701, 0.7704, 0.7707, 0.7708, 0.7709999999999999, 0.7715, 0.7725, 0.7727, 0.7731, 0.7747, 0.775, 0.7751, 0.7767, 0.7771, 0.7775, 0.7779, 0.7781, 0.7784, 0.7786, 0.7789, 0.78, 0.7806, 0.7808, 0.7813, 0.7816, 0.7825, 0.7835, 0.7846, 0.7849, 0.7859, 0.7863, 0.7878, 0.7892, 0.7902, 0.7904, 0.7909, 0.7922, 0.7931, 0.7934, 0.7937, 0.7941, 0.7948, 0.8002, 0.8003, 0.8005, 0.8011, 0.8013, 0.8037, 0.8039, 0.8056, 0.8059, 0.8059999999999999, 0.8067, 0.807, 0.8079999999999999, 0.8087, 0.8106, 0.8121, 0.8132, 0.8133, 0.8141, 0.8142, 0.8155, 0.8163, 0.8175, 0.8188, 0.8193, 0.821, 0.8224, 0.8225, 0.8245, 0.8252, 0.8258, 0.8259, 0.8266, 0.8271, 0.8282, 0.8289, 0.8298, 0.8314, 0.8316, 0.8317, 0.8336, 0.8340000000000001, 0.8347, 0.8348, 0.8351, 0.8376, 0.8385, 0.8392, 0.84, 0.8413, 0.8434, 0.8443, 0.8444, 0.8451, 0.8458, 0.8498, 0.8518, 0.8521, 0.8525, 0.8537, 0.8549, 0.858, 0.8584, 0.8619, 0.8640000000000001, 0.8662, 0.8732, 0.8736, 0.8737, 0.8791, 0.88, 0.8828, 0.8829, 0.8859, 0.8866, 0.8868, 0.8869, 0.8885, 0.889, 0.8897, 0.8909999999999999, 0.8944, 0.8951, 0.8955, 0.8957, 0.8958, 0.8974, 0.8975, 0.8994, 0.9005, 0.9007, 0.9018, 0.9062, 0.9064, 0.9067, 0.9075, 0.9079999999999999, 0.9082, 0.9091, 0.9093, 0.9132, 0.9141, 0.9155, 0.9158, 0.9177, 0.9194, 0.9205, 0.9207, 0.9216, 0.9221, 0.9236, 0.9246, 0.927, 0.9283, 0.9286, 0.9296, 0.9323, 0.9358, 0.9413, 0.9436, 0.9448, 0.9457, 0.9470000000000001, 0.9477, 0.9539, 0.9559, 0.9570000000000001, 0.9574, 0.9579, 0.9583, 0.9635, 0.9654, 0.9667, 0.9675, 0.9682, 0.9714, 0.9744, 0.9749, 0.9754, 0.9764, 0.9791, 0.9798, 0.9822, 0.9851, 0.9854, 0.9874, 0.9878, 0.9938]\n",
      "\n",
      "Something went wrong. Sleeping 5 seconds.\n",
      "\n",
      "0 Classifiers [00:15, ? Classifiers/s]\u001b[A\n",
      "Walltime budget has run out!\n",
      "Datarun 8 has ended.\n",
      "0 Classifiers [00:00, ? Classifiers/s]\n"
     ]
    }
   ],
   "source": [
    "results4 = atm.run(\n",
    "    train_path='/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Regression_fixed.csv',\n",
    "    test_path = None, #default, splits train set automatically\n",
    "    name = 'Regression_Set',\n",
    "    class_column = 'percent_pell_grant',\n",
    "    budget = 1,\n",
    "    budget_type = 'walltime',\n",
    "    gridding = 0, #default 0 no gridding, gridding factor\n",
    "    k_window = 0, #default\n",
    "    methods = ['logreg', 'dt', 'knn'], #default\n",
    "    metric = 'f1', #default\n",
    "    r_minimum = 2, #default\n",
    "    run_per_partition = False, #default\n",
    "    score_target = 'cv', #default\n",
    "    #priority = '', #no default given\n",
    "    selector = 'uniform', #default\n",
    "    tuner = 'uniform'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd7d1ea-a314-48cc-b7d2-6b8070452bcf",
   "metadata": {},
   "source": [
    "# Datenbereinigung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8907c7-78af-4530-a67a-e3be4bc4866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bei pishing (classification) Datei mit text editor im Header die Anführungszeichen von '' auf \"\" geändert damit es läuft\n",
    "#bei college (Regression) Datei:\n",
    "import pandas as pd\n",
    "#aus der gegebenen csv zunächst die erste (header) Zeile per Text Editor mit ,'' auffüllen um dort die maximale Spaltenanzahl wiederzuspiegeln\n",
    "df = pd.read_csv('/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Datasets/college_test_firstlinefilled.csv')\n",
    "#Leere Zellen mit ? gefüllt\n",
    "df = df.fillna('?') #das war nötig um überhaupt etwas zu starten. Da Regression per ATM nicht unterstützt wird hätte man sich das sparen können aber ich wollte es testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a80e24-82d4-4f24-97aa-952c0d42b1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'UNITID'</th>\n",
       "      <th>'school_name'</th>\n",
       "      <th>'city'</th>\n",
       "      <th>'state'</th>\n",
       "      <th>'zip'</th>\n",
       "      <th>'school_webpage'</th>\n",
       "      <th>'latitude'</th>\n",
       "      <th>'longitude'</th>\n",
       "      <th>'admission_rate'</th>\n",
       "      <th>'sat_verbal_midrange'</th>\n",
       "      <th>...</th>\n",
       "      <th>000 to 9</th>\n",
       "      <th>999)'</th>\n",
       "      <th>?.3</th>\n",
       "      <th>0.52999997138977</th>\n",
       "      <th>0.07999999821186</th>\n",
       "      <th>40211.22</th>\n",
       "      <th>26100.0</th>\n",
       "      <th>22800.0</th>\n",
       "      <th>35300.0</th>\n",
       "      <th>31400.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>422695</td>\n",
       "      <td>'Pacific College'</td>\n",
       "      <td>'Costa Mesa'</td>\n",
       "      <td>CA</td>\n",
       "      <td>92626</td>\n",
       "      <td>pacific-college.com</td>\n",
       "      <td>33.6813</td>\n",
       "      <td>-117.8732</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>422835</td>\n",
       "      <td>'American College of Healthcare'</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>CA</td>\n",
       "      <td>92505</td>\n",
       "      <td>www.ach.edu</td>\n",
       "      <td>33.9005</td>\n",
       "      <td>-117.4938</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423120</td>\n",
       "      <td>'Compu-Med Vocational Careers Corp'</td>\n",
       "      <td>Hialeah</td>\n",
       "      <td>FL</td>\n",
       "      <td>33012-4861</td>\n",
       "      <td>compumedschool.com</td>\n",
       "      <td>25.8484</td>\n",
       "      <td>-80.3069</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423397</td>\n",
       "      <td>'Professional Electrical School Inc'</td>\n",
       "      <td>Manati</td>\n",
       "      <td>PR</td>\n",
       "      <td>674</td>\n",
       "      <td>www.peseducate.com</td>\n",
       "      <td>18.428</td>\n",
       "      <td>-66.4931</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423582</td>\n",
       "      <td>'American Commercial College-Wichita Falls'</td>\n",
       "      <td>'Wichita Falls'</td>\n",
       "      <td>TX</td>\n",
       "      <td>76310</td>\n",
       "      <td>www.americancommercialcollege.com</td>\n",
       "      <td>33.8699</td>\n",
       "      <td>-98.5771</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   'UNITID'                                'school_name'           'city'  \\\n",
       "0    422695                            'Pacific College'     'Costa Mesa'   \n",
       "1    422835             'American College of Healthcare'        Riverside   \n",
       "2    423120          'Compu-Med Vocational Careers Corp'          Hialeah   \n",
       "3    423397         'Professional Electrical School Inc'           Manati   \n",
       "4    423582  'American Commercial College-Wichita Falls'  'Wichita Falls'   \n",
       "\n",
       "  'state'       'zip'                   'school_webpage' 'latitude'  \\\n",
       "0      CA       92626                pacific-college.com    33.6813   \n",
       "1      CA       92505                        www.ach.edu    33.9005   \n",
       "2      FL  33012-4861                 compumedschool.com    25.8484   \n",
       "3      PR         674                 www.peseducate.com     18.428   \n",
       "4      TX       76310  www.americancommercialcollege.com    33.8699   \n",
       "\n",
       "  'longitude' 'admission_rate' 'sat_verbal_midrange'  ... 000 to 9 999)' ?.3  \\\n",
       "0   -117.8732                ?                     ?  ...        ?     ?   ?   \n",
       "1   -117.4938                ?                     ?  ...        ?     ?   ?   \n",
       "2    -80.3069                ?                     ?  ...        ?     ?   ?   \n",
       "3    -66.4931                ?                     ?  ...        ?     ?   ?   \n",
       "4    -98.5771                ?                     ?  ...        ?     ?   ?   \n",
       "\n",
       "  0.52999997138977 0.07999999821186 40211.22 26100.0  22800.0  35300.0  \\\n",
       "0                ?                ?        ?       ?        ?        ?   \n",
       "1                ?                ?        ?       ?        ?        ?   \n",
       "2                ?                ?        ?       ?        ?        ?   \n",
       "3                ?                ?        ?       ?        ?        ?   \n",
       "4                ?                ?        ?       ?        ?        ?   \n",
       "\n",
       "   31400.0  \n",
       "0        ?  \n",
       "1        ?  \n",
       "2        ?  \n",
       "3        ?  \n",
       "4        ?  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84a8a406-a25d-4813-9d0a-9feb6bf39ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/gerritscheeppat/Documents/OneDrive/Studium/Data Science/03_WS2122/Hauptseminar-AutoML/Regression_test_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e883127d-9d32-4c2b-b925-957203123859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any(axis = 1).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
